{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/A+ysnRvlZ2MSaxGtkAkz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masadeghi/journal_finder/blob/main/journal_finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone GitHub repo to have access to datasets\n",
        "\n",
        "**Note: journal encodings are available in the 'journal_scope_encodings' directory of the github repo. You could skip to the 'Define function that computes similarity ...' section if you load the encodings from these .pkl files.**"
      ],
      "metadata": {
        "id": "vDp1-glfvg7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/masadeghi/journal_finder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2_33PEYvcpC",
        "outputId": "fc87d4ec-09dc-42d0-cf26-2f43cc8e0fcd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'journal_finder'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 19 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (19/19), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read datasets containing the scope of each journal\n",
        "\n",
        "These datasets were generated from our scimago_scrape.py script."
      ],
      "metadata": {
        "id": "ne2imHubvAwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read datasets and drop journals without a scope\n",
        "def read_journal_dataset(file_path):\n",
        "  \"\"\"\n",
        "  Given the file_path of a journal information dataset, read the file as a pandas\n",
        "  DataFrame and drop journals without a scope.\n",
        "\n",
        "  Args:\n",
        "    file_path (str): The path of a .csv file containing the journal information\n",
        "  \n",
        "  Returns:\n",
        "    dataset (DataFrame): A pandas DataFrame of journal information.\n",
        "  \"\"\"\n",
        "  dataset = pd.read_csv(file_path)\n",
        "  dataset.dropna(axis = 0, subset = [\"Scope\"], inplace = True) # Drop rows without a scope\n",
        "  dataset = dataset.reset_index(drop = True) # Reset indices\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "YrPTwdUwXmov"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# biochem_molbio_dataset = read_journal_dataset(file_path)\n",
        "# immuno_micro_dataset = read_journal_dataset(file_path)\n",
        "# med_dataset = read_journal_dataset(file_path)\n",
        "neuro_dataset = read_journal_dataset(\"/content/journal_finder/scraped_from_scimago/neuro_journals.csv\")\n",
        "pharma_toxico_dataset = read_journal_dataset(\"/content/journal_finder/scraped_from_scimago/pharma_toxico_journals.csv\")"
      ],
      "metadata": {
        "id": "j9oFqDKcwGO6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pharma_toxico_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yGiu7a7EwWlI",
        "outputId": "5752a798-eed4-47c0-80f2-e4ae7458a7c9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Rank    Sourceid                                           Title     SJR  \\\n",
              "0     1       20425                 \"Nature Reviews Drug Discovery\"  11.296   \n",
              "1     2       21191                       \"Pharmacological Reviews\"   5.540   \n",
              "2     3       19479  \"Annual Review of Pharmacology and Toxicology\"   4.002   \n",
              "3     4  4700152457                                    \"Nano Today\"   3.890   \n",
              "4     5       12611                       \"Drug Resistance Updates\"   3.845   \n",
              "\n",
              "  SJR Best Quartile                                                URL  \\\n",
              "0                Q1  https://www.scimagojr.com/journalsearch.php?q=...   \n",
              "1                Q1  https://www.scimagojr.com/journalsearch.php?q=...   \n",
              "2                Q1  https://www.scimagojr.com/journalsearch.php?q=...   \n",
              "3                Q1  https://www.scimagojr.com/journalsearch.php?q=...   \n",
              "4                Q1  https://www.scimagojr.com/journalsearch.php?q=...   \n",
              "\n",
              "                                               Scope  \n",
              "0  nature reviews drug discovery is a monthly jou...  \n",
              "1  pharmacological reviews presents important rev...  \n",
              "2  the annual review of pharmacology and toxicolo...  \n",
              "3  nano today publishes original articles on all ...  \n",
              "4  drug resistance updates is a bimonthly publica...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70362ccb-dae5-4351-b374-c73a1debc734\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rank</th>\n",
              "      <th>Sourceid</th>\n",
              "      <th>Title</th>\n",
              "      <th>SJR</th>\n",
              "      <th>SJR Best Quartile</th>\n",
              "      <th>URL</th>\n",
              "      <th>Scope</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20425</td>\n",
              "      <td>\"Nature Reviews Drug Discovery\"</td>\n",
              "      <td>11.296</td>\n",
              "      <td>Q1</td>\n",
              "      <td>https://www.scimagojr.com/journalsearch.php?q=...</td>\n",
              "      <td>nature reviews drug discovery is a monthly jou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>21191</td>\n",
              "      <td>\"Pharmacological Reviews\"</td>\n",
              "      <td>5.540</td>\n",
              "      <td>Q1</td>\n",
              "      <td>https://www.scimagojr.com/journalsearch.php?q=...</td>\n",
              "      <td>pharmacological reviews presents important rev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>19479</td>\n",
              "      <td>\"Annual Review of Pharmacology and Toxicology\"</td>\n",
              "      <td>4.002</td>\n",
              "      <td>Q1</td>\n",
              "      <td>https://www.scimagojr.com/journalsearch.php?q=...</td>\n",
              "      <td>the annual review of pharmacology and toxicolo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>4700152457</td>\n",
              "      <td>\"Nano Today\"</td>\n",
              "      <td>3.890</td>\n",
              "      <td>Q1</td>\n",
              "      <td>https://www.scimagojr.com/journalsearch.php?q=...</td>\n",
              "      <td>nano today publishes original articles on all ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>12611</td>\n",
              "      <td>\"Drug Resistance Updates\"</td>\n",
              "      <td>3.845</td>\n",
              "      <td>Q1</td>\n",
              "      <td>https://www.scimagojr.com/journalsearch.php?q=...</td>\n",
              "      <td>drug resistance updates is a bimonthly publica...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70362ccb-dae5-4351-b374-c73a1debc734')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70362ccb-dae5-4351-b374-c73a1debc734 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70362ccb-dae5-4351-b374-c73a1debc734');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding the journal scopes\n",
        "\n",
        "To do this, we utilize the pretrained BERT model by google which has been trained on MEDLINE/Pubmed data. The model description may be found here:\n",
        "\n",
        "https://tfhub.dev/google/experts/bert/pubmed/2"
      ],
      "metadata": {
        "id": "YUOULH-_wZqw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import model from TensorFlow Hub"
      ],
      "metadata": {
        "id": "GH3DcmnS3pSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jNNMA2ceXeTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "341c0ef4-ea66-435c-a4c1-ead65907b338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-text==2.8.* in /usr/local/lib/python3.7/dist-packages (2.8.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.8.*) (2.8.4)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.14.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.21.6)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (22.11.23)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.19.6)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.27.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (14.0.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text==2.8.*) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install \"tensorflow-text==2.8.*\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "# Imports TF ops for preprocessing.\n",
        "import tensorflow_text as text\n",
        "\n",
        "# Load the BERT encoder and preprocessing models\n",
        "preprocess = hub.load('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "bert = hub.load('https://tfhub.dev/google/experts/bert/pubmed/2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function for encoding a single string"
      ],
      "metadata": {
        "id": "YJuhwI7m3tCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_string_encoding(text):\n",
        "  \"\"\"\n",
        "  Given a string, calculate it's encoding using BERT.\n",
        "\n",
        "  Args:\n",
        "    text (str): The text to be encoded.\n",
        "\n",
        "  Returns:\n",
        "    encoding (tenosr): A tensor of shape (1, 768) containing the pooled_output\n",
        "    of the BERT model.\n",
        "  \"\"\"\n",
        "  text_list = [text]\n",
        "  \n",
        "  # Convert the text to bert inputs\n",
        "  bert_inputs = preprocess(text_list)\n",
        "\n",
        "  # Feed the inputs to the model to get the pooled output\n",
        "  bert_outputs = bert(bert_inputs, training=False)\n",
        "  pooled_output = bert_outputs['pooled_output']\n",
        "\n",
        "  return pooled_output"
      ],
      "metadata": {
        "id": "KBadYQ0S0saK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define function for encoding a list of strings"
      ],
      "metadata": {
        "id": "1ppqY8T93xJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_journal_encodings(dataset):\n",
        "\n",
        "  # Initialize a dictionary for the journal encoding tensors\n",
        "  journal_encodings = {}\n",
        "\n",
        "  # Convert journal scopes and titles from DataFrame columns to lists to reduce RAM usage\n",
        "  journal_scopes = dataset.loc[:, 'Scope'].tolist()\n",
        "  journal_names = dataset.loc[:, 'Title'].tolist()\n",
        "\n",
        "  # Due to limitations in RAM capacity on the free version of Colab,\n",
        "  # we run the code for a maximum of 2000 journals\n",
        "  if len(journal_scopes) > 2000:\n",
        "    for i in range(2000):\n",
        "      text = journal_scopes[i]\n",
        "      encoding = get_string_encoding(text)\n",
        "      journal_encodings[journal_names[i]] = encoding\n",
        "  else:\n",
        "    for i in range(len(journal_scopes)):\n",
        "      text = journal_scopes[i]\n",
        "      encoding = get_string_encoding(text)\n",
        "      journal_encodings[journal_names[i]] = encoding\n",
        "\n",
        "  if i % 100 == 0 and i != 0:\n",
        "    print(f\"Successfully gone through {i} scopes\")\n",
        "  \n",
        "  return journal_encodings"
      ],
      "metadata": {
        "id": "QWH096Qwe4KU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the encodings for each dataset"
      ],
      "metadata": {
        "id": "39DBfAiZ31yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# biochem_molbio_encodings = get_journal_encodings(biochem_molbio_dataset)\n",
        "# immuno_micro_encodings = get_journal_encodings(immuno_micro_dataset)\n",
        "# med_encodings = get_journal_encodings(med_dataset)\n",
        "# neuro_encodings = get_journal_encodings(neuro_dataset)\n",
        "pharma_toxico_encodings = get_journal_encodings(pharma_toxico_dataset)"
      ],
      "metadata": {
        "id": "04YVtEHj3Djx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save journal encodings"
      ],
      "metadata": {
        "id": "uIJLOrwNLmT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def save_dict(dict, name):\n",
        "  output_file = name + '.pkl'\n",
        "  f = open(output_file, \"wb\")\n",
        "  pickle.dump(dict,f)\n",
        "  f.close()"
      ],
      "metadata": {
        "id": "x7ItpY7eUSNz"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save_dict(biochem_molbio_encodings, \"biochem_molbio_encodings\")\n",
        "# save_dict(immuno_micro_encodings, \"immuno_micro_encodings\")\n",
        "# save_dict(med_encodings, \"med_encodings\")\n",
        "# save_dict(neuro_encodings, \"neuro_encodings\")\n",
        "save_dict(pharma_toxico_encodings, \"pharma_toxico_encodings\")"
      ],
      "metadata": {
        "id": "kwONYGMDTzwg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the cosine similarity function as a measure of similarity between two vectors"
      ],
      "metadata": {
        "id": "-5JLzCPq343Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(abstract_encoding, journal_encoding):\n",
        "  abstract_encoding = tf.cast(abstract_encoding, dtype = tf.float32)\n",
        "  journal_encoding = tf.cast(journal_encoding, dtype = tf.float32)\n",
        "  numerator = tf.matmul(abstract_encoding, tf.transpose(journal_encoding))\n",
        "  denominator = tf.norm(abstract_encoding) * tf.norm(journal_encoding)\n",
        "  return numerator/denominator"
      ],
      "metadata": {
        "id": "Ubjn28QucG-2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define function that computes similarity between abstract and journal list"
      ],
      "metadata": {
        "id": "P2MDTqyR4YCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def similar_journals():\n",
        "  \"\"\"\n",
        "  Ask the user to input their manuscript abstract, desired subject category, and\n",
        "  the number of journals they would like to see.\n",
        "  \n",
        "  Returns\n",
        "    A list of journal names and their similarity scores\n",
        "  \"\"\"\n",
        "  abstract = input(\"Paste your manuscript abstract:\")\n",
        "  category = input(\"Choose your manuscript subject category:\\n1) Biochemistry, Genetics, and Molecular Biology\\n2) Immunology and Microbiology\\n3) Medicine\\n4) Neuroscience\\n5) Pharmacology, Toxicology and Pharmaceutics [1/2/3/4/5]\")\n",
        "  number = input(\"How many journals would you like to see?\")\n",
        "\n",
        "  if category == '1':\n",
        "    dataset = biochem_molbio_encodings\n",
        "  elif category == '2':\n",
        "    dataset = immuno_micro_encodings\n",
        "  elif category == '3':\n",
        "    dataset = med_encodings\n",
        "  elif category == '4':\n",
        "    dataset = neuro_encodings\n",
        "  elif category == '5':\n",
        "    dataset = pharma_toxico_encodings\n",
        "  else:\n",
        "    print(\"Please rerun the program and enter a valid category.\")\n",
        "\n",
        "  # Get bert encoding of abstract\n",
        "  abstract_encoding = get_string_encoding(abstract)\n",
        "\n",
        "  # Compute similarity scores between abstract encodings and journal scope encodings\n",
        "  similarity_scores = []\n",
        "\n",
        "  for name, journal_encoding in dataset.items():\n",
        "    similarity = cosine_similarity(abstract_encoding, journal_encoding)\n",
        "    similarity = similarity[0][0]\n",
        "    similarity_scores.append(similarity)\n",
        "\n",
        "  sorted_indices = sorted(\n",
        "      range(len(similarity_scores)),\n",
        "      key = lambda index: similarity_scores[index],\n",
        "      reverse = True\n",
        "  )\n",
        "\n",
        "  sorted_journal_names = [list(dataset)[index] for index in sorted_indices]\n",
        "  sorted_similarity_scores = [similarity_scores[index] for index in sorted_indices]\n",
        "\n",
        "  output = pd.DataFrame.from_dict({'Title' : sorted_journal_names,\n",
        "                                  'Similarity score' : sorted_similarity_scores})\n",
        "  \n",
        "  print(output[:int(number)])\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "oCGdgtGJgt-y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the function"
      ],
      "metadata": {
        "id": "Okd0o5mqAOGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommended_journals = similar_journals()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwSpXcaHEBST",
        "outputId": "905b0b0d-1a2a-4eda-a333-a707a1bd759d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paste your manuscript abstract:Current pharmacological treatments against post-traumatic stress disorder (PTSD) lack adequate efficacy. As a result, intense research has focused on identifying other molecular pathways mediating the pathogenesis of this condition. One such pathway is neuroinflammation, which has demonstrated a role in PTSD pathogenesis by causing synaptic dysfunction, neuronal death, and functional impairment in the hippocampus. Phosphodiesterase (PDE) inhibitors (PDEIs) have emerged as promising therapeutic agents against neuroinflammation in other neurological conditions. Furthermore, PDEIs have shown some promise in animal models of PTSD. However, the current model of PTSD pathogenesis, which is based on dysregulated fear learning, implies that PDE inhibition in neurons should enhance the acquisition of fear memory from the traumatic event. As a result, we hypothesized that PDEIs may improve PTSD symptoms through inhibiting neuroinflammation rather than learning and long-term potentiation-related mechanisms. To this end, we tested the therapeutic efficacy of cilostazol, a selective inhibitor of PDE3, in the underwater trauma model of PTSD. PDE3 is expressed much more richly in microglia and astrocytes compared to neurons in the murine brain. Furthermore, we used hippocampal indolamine 2,3-dioxigenase 1 (IDO) expression as an indicator of neuroinflammation. We observed that cilostazol treatment reduced PTSD-related anxiety symptoms. This therapeutic effect was associated with a reduction of IDO expression, which was increased upon PTSD induction. In conclusion, PDE3 may play a role in the neuroinflammatory processes involved in abnormal fear acquisition during PTSD pathogenesis. As a result, cilostazol and other PDEIs may be promising candidates for further investigation as pharmacological therapies against PTSD.\n",
            "Choose your manuscript subject category:\n",
            "1) Biochemistry, Genetics, and Molecular Biology\n",
            "2) Immunology and Microbiology\n",
            "3) Medicine\n",
            "4) Neuroscience\n",
            "5) Pharmacology, Toxicology and Pharmaceutics [1/2/3/4/5]5\n",
            "How many journals would you like to see?20\n",
            "                                                Title  \\\n",
            "0          \"Drug Delivery and Translational Research\"   \n",
            "1                 \"Molecular and Cellular Toxicology\"   \n",
            "2                                     \"PPAR Research\"   \n",
            "3                  \"International Immunopharmacology\"   \n",
            "4                            \"Geneesmiddelenbulletin\"   \n",
            "5                 \"CNS Neuroscience and Therapeutics\"   \n",
            "6                         \"Investigational New Drugs\"   \n",
            "7                    \"Journal of Pharmacy Technology\"   \n",
            "8                       \"Journal of Pharmacopuncture\"   \n",
            "9                             \"Vascular Pharmacology\"   \n",
            "10                      \"Journal of Natural Products\"   \n",
            "11                           \"Phytochemical Analysis\"   \n",
            "12                            \"Current Drug Delivery\"   \n",
            "13         \"DARU, Journal of Pharmaceutical Sciences\"   \n",
            "14         \"Nanotechnology, Science and Applications\"   \n",
            "15                      \"Cell Biology and Toxicology\"   \n",
            "16                       \"Journal of Texture Studies\"   \n",
            "17  \"Boletin Latinoamericano y del Caribe de Plant...   \n",
            "18                          \"Drug Metabolism Reviews\"   \n",
            "19  \"Journal of Exposure Science and Environmental...   \n",
            "\n",
            "                                  Similarity score  \n",
            "0    tf.Tensor(0.8601944, shape=(), dtype=float32)  \n",
            "1   tf.Tensor(0.84339124, shape=(), dtype=float32)  \n",
            "2   tf.Tensor(0.83618855, shape=(), dtype=float32)  \n",
            "3    tf.Tensor(0.8350082, shape=(), dtype=float32)  \n",
            "4    tf.Tensor(0.8334402, shape=(), dtype=float32)  \n",
            "5    tf.Tensor(0.8327885, shape=(), dtype=float32)  \n",
            "6   tf.Tensor(0.82945687, shape=(), dtype=float32)  \n",
            "7    tf.Tensor(0.8294063, shape=(), dtype=float32)  \n",
            "8   tf.Tensor(0.82738143, shape=(), dtype=float32)  \n",
            "9   tf.Tensor(0.82697034, shape=(), dtype=float32)  \n",
            "10    tf.Tensor(0.824877, shape=(), dtype=float32)  \n",
            "11  tf.Tensor(0.82471246, shape=(), dtype=float32)  \n",
            "12   tf.Tensor(0.8243202, shape=(), dtype=float32)  \n",
            "13    tf.Tensor(0.824212, shape=(), dtype=float32)  \n",
            "14   tf.Tensor(0.8233835, shape=(), dtype=float32)  \n",
            "15   tf.Tensor(0.8228459, shape=(), dtype=float32)  \n",
            "16  tf.Tensor(0.82257015, shape=(), dtype=float32)  \n",
            "17  tf.Tensor(0.82248074, shape=(), dtype=float32)  \n",
            "18   tf.Tensor(0.8211878, shape=(), dtype=float32)  \n",
            "19  tf.Tensor(0.82044053, shape=(), dtype=float32)  \n"
          ]
        }
      ]
    }
  ]
}